{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7ce0f1-a278-48f8-b2d0-1de5be74c7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as td\n",
    "\n",
    "from mapleetz.individual import TorchModuleIndividual, Individual\n",
    "from mapleetz.evaluate_fn import GymEvaluateFunction, EvaluateOutput\n",
    "from mapleetz.map import GridMap\n",
    "from mapleetz.map_elites import MapElites\n",
    "from mapleetz.mutation import CrossoverMutation, GaussianNoiseMutation, Mutation, MutationSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5f0ab6-8e58-4025-9804-76693782a54b",
   "metadata": {},
   "source": [
    "## LunarLander policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c547050-6745-4166-9d7c-10a07c4bd93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LunarLanderPolicy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_dims = 8\n",
    "        self.action_dims = 4\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, state) -> torch.Tensor:\n",
    "        state = state.float()\n",
    "        output = self.network(state)\n",
    "        dist = td.Categorical(logits=output)\n",
    "        return dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb04fe0-4956-4f49-8298-e1c8eb219b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy = LunarLanderPolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700eccae-7a31-4869-b9b4-eab847c28821",
   "metadata": {},
   "source": [
    "## Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62e656-8f7e-4173-86d2-9ad6901186cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(model, seed=None, video_env=None):\n",
    "    \"\"\"Simulates the lunar lander model.\n",
    "\n",
    "    Args:\n",
    "        model (np.ndarray): The array of weights for the linear policy.\n",
    "        seed (int): The seed for the environment.\n",
    "        video_env (gym.Env): If passed in, this will be used instead of creating\n",
    "            a new env. This is used primarily for recording video during\n",
    "            evaluation.\n",
    "    Returns:\n",
    "        total_reward (float): The reward accrued by the lander throughout its\n",
    "            trajectory.\n",
    "        impact_x_pos (float): The x position of the lander when it touches the\n",
    "            ground for the first time.\n",
    "        impact_y_vel (float): The y velocity of the lander when it touches the\n",
    "            ground for the first time.\n",
    "    \"\"\"\n",
    "    if video_env is None:\n",
    "        # Since we are using multiple processes, it is simpler if each worker\n",
    "        # just creates their own copy of the environment instead of trying to\n",
    "        # share the environment. This also makes the function \"pure.\" However,\n",
    "        # we should use the video_env if it is passed in.\n",
    "        env = gym.make(\"LunarLander-v2\")\n",
    "    else:\n",
    "        env = video_env\n",
    "\n",
    "    action_dim = env.action_space.n\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    model = model.reshape((action_dim, obs_dim))\n",
    "\n",
    "    total_reward = 0.0\n",
    "    impact_x_pos = None\n",
    "    impact_y_vel = None\n",
    "    all_y_vels = []\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    states = [obs]\n",
    "    while not done:\n",
    "        action = np.argmax(model @ obs)  # Linear policy.\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        states.append(obs)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "\n",
    "        # Refer to the definition of state here:\n",
    "        # https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
    "        x_pos = obs[0]\n",
    "        y_vel = obs[3]\n",
    "        leg0_touch = bool(obs[6])\n",
    "        leg1_touch = bool(obs[7])\n",
    "        all_y_vels.append(y_vel)\n",
    "\n",
    "        # Check if the lunar lander is impacting for the first time.\n",
    "        if impact_x_pos is None and (leg0_touch or leg1_touch):\n",
    "            impact_x_pos = x_pos\n",
    "            impact_y_vel = y_vel\n",
    "\n",
    "    # If the lunar lander did not land, set the x-pos to the one from the final\n",
    "    # timestep, and set the y-vel to the max y-vel (we use min since the lander\n",
    "    # goes down).\n",
    "    if impact_x_pos is None:\n",
    "        impact_x_pos = x_pos\n",
    "        impact_y_vel = min(all_y_vels)\n",
    "\n",
    "    # Only close the env if it was not a video env.\n",
    "    if video_env is None:\n",
    "        env.close()\n",
    "\n",
    "    return EvaluateOutput(fitness=total_reward, np.array([impact_x_pos, impact_y_vel]), states=states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
